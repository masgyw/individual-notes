# MQ
消息队列：利用队列来进行通信的组件。  

## 为什么要用MQ
解耦、异步、削峰  
1）解耦：系统解耦，各个系统相互独立，自主选择需要什么数据  
2）异步：对于不太实时的系统调用，可以异步调用，提高请求的实时返回速度  
3）削峰：减少突增的请求对服务器的压力  
## 消息队列基本概念
1）两种模型：队列模型、发布/订阅模型  
发布订阅兼容队列模型。  
RabbitMQ 使用队列模式，全量分发多个队列，实现一个消息多消费。  
RocketMQ 和 Kafka 采用发布/订阅模型  
2）常用术语：  
发布订阅引入队列或分区的概念。Topic 下有多个队列或多个分区，概念类似。  
生产者轮询将消息发送到Topic 下的多个队列，消费者维护队列读取的offset。

## MQ 的优缺点
优点：解耦、异步、削峰  
缺点：  
1）可用性降低：增加了中间件，降低了系统的可用性  
2）复杂性提高：消息丢失、消息重复、消息顺序，增加了系统的复杂性  
3）一致性问题：ABCD四个系统，ABC系统处理成功，D系统处理失败，系统间的数据会存在不一致问题
## 常用MQ 之间的对比

| 指标 | Kafka | ActiveMQ | RabbitMQ | RocketMQ |
| --- | --- | --- | --- | --- |
|吞吐量 | 高 | 低 | 低 | 高 |
|延迟率|||高||
|社区活跃度|||高||
|持久化消息|追加写入日志文件|是|是|否|
|综合技术| 最好|次|最好||
|高并发|||好||
|可用性|分布式|主从|主从|分布式|
|时效性|ms|ms|us|ms|

总结：Kafka 针对日志处理，大数据日志分析。中小型公司，业务处理不复杂，建议使用RabbitMQ，主从保证高可用，社区活跃，有完善的管理端。大型公司，可以考虑RocketMQ，阿里系，在高并发的环境下经过验证，分布式业务，支持复杂业务，但是公司维护，如果哪天公司不维护了，技术问题很难解决。ActivityMQ 社区不活跃，有一定的数据丢失可能。

## 如何保证高可用

1）RabbitMQ   

rabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。  
- 单机模式：demo级别的，生产环境不会用。  

- 普通集群模式：多台机器上启动多个RabbitMQ，每台机器启动一个。创建的queue，只会在一个RabbitMQ实例上，每个实例都同步queue的元数据，消费时，如果连接了其他实例，那么实例会根据元数据从queue所在的实例上拉取数据，提高吞吐量。  

- 镜像集群模式：真正的高可用模式。queue 和元数据都会在每个实例上，写消息时，会自动同步消息到每个实例queue上。可以通过管理端控制台，添加镜像集群策略，可以指定消息同步到所有还是部分节点上，再次创建queue时，应用策略，就可以将数据自动同步到其他节点上。  
优点：高可用，如果一个节点挂了，还有其他节点可以提供服务，其他节点有完整的queue。  
缺点：性能开销大，消息需要同步到其他机器上，导致机器带宽压力和消耗严重。  

2）Kafka MQ  
- Kafka 基础架构:
由多个broker组成，每个broker是一个节点；创建一个topic，topic可以分为多个partition，每个partition可以存在不同的broker上，每个partition就放一部分数据，所以是分布式消息队列，一个topic数据，分散到多个机器上，每个机器就放一部分数据。  
- HA 机制：replica副本机制  
每个partition的数据会同步到其它机器上，形成自己的多个replica副本。partitions存在leader-follower角色，生产和消费都只和leader打交道，写的时候，leader将数据同步到其他follower上，读的时候直接读leader上的数据即可。注意：只能读写leader，为了避免数据一致性问题。如果broker挂了，其他broker上还有partition的数据，如果机器上是leader partion，那就选举出新的leader。  

## 如何保证消息可靠传输？消息丢失了怎么办？
消息不能少，消息丢失的问题，可能发生在生产者/MQ/消费者中。  
rabbitMQ：
1. 生产者丢失  
网络问题，可能数据在发送过程中丢失了，必须进行异常处理，进行重试、告警等。  
方案一：RabbitMQ 提供事务功能  
生产者发送数据之前，开启RabbitMQ事务（channel.txSelect），然后在try{}catch{} 中发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息,那么可以提交事务channel.txCommit。缺点是：同步机制，吞吐量会下来，太耗性能。  
方案二：开启confirm模式  
每次写的消息都会分配一个唯一的id，如果写入rabbitMQ，rabbitMQ会返回一个ack确认消息。如果没有写入，会回调你一个nack接口，告诉你消息接收失败，可以重试。结合这个机制可以在内存里维护每个消息id 的状态，如果超过一定时间没有接收到消息的回调，可以重发。  
分析：事务机制和confirm机制最大的区别是：事务机制同步阻塞，confirm机制异步非阻塞，一般使用confirm机制，吞吐量高一点。  
2. MQ丢失  
rabbitMQ将数据存储在内存中，重启后，丢失数据。  
方案：开启RabbitMQ 的持久化，数据写入到磁盘，即使服务器挂了，也可以数据恢复。  
设置持久化：  
1）创建持久化的queue，持久化queue的元数据，但不会持久化queue中的数据；  
2）发送的消息设置deliveryMode=2，持久化消息；  
配合confirm 机制，只有数据持久化后，才会通知生产者ack。
3. 消费者丢失  
autoAck机制下，消息到达消费者，还未处理，进程挂了，rabbitMQ 认为消息消费了，数据删除丢失了。  
方案：使用RabbitMQ 提供的ack机制，关闭自动ack，通过api调用，程序消费完消息后，由程序ack。如果还没有消费完，rabbitMQ 会将消费分配给其他消费者，消息不会丢失的。  
说明：可靠性提高了，但是性能会降低，例如日志的传输，如果丢失影响不大。

Kafka：
1. 生产者丢失  
如果设置了acks=all，retries=MAX，生产者一定不会丢，因为参数设置需要leader接收消息，所有follower同步消息成功后，才认为数据写成功了。
2. MQ丢失  
kafka 某个broker在同步数据时机器宕机，follower切换到leader之后，部分没有同步过来的数据就丢失了。  
方案：设置如下4个参数  
1）设置topic的replication.factor 参数必须大于1，要求每个partition的副本必须至少2个  
2）服务端设置min.insync.replicas 参数必须大于1，至少有一个follower和leader保持正常的数据同步和通信  
3）producer设置acks=all，生产者写的每条消息，必须写入所有replica副本后，才可以ack写入成功  
4）producer设置retries=MAX（大值），一旦写入失败，无限重试  
3. 消费者丢失：消费者自动提交offset，MQ认为消息已被消费，可能消息还未被消费，导致消息丢失。  
方案：关闭自动提交offset，由程序手动提交offset。

## 如何处理重复消息
消息不能多！  
1）Kafka 消费端可能出现的重复消息的问题：
生产者生产的每条消息都会有一个offset，按照数据进入kafka的顺序，代表了这个消息的顺序。消费者消费数据后，会提交offset，告诉kafka已经消费的消息。问题在于kafka消费者提交是定时定期的，不是实时的，在消费者准备提交时重启，kafka会把已经消费的offset消息重新发送一次  
2）能否避免重复消息  
如果Producer只管发，不重试，是不会有重复消息的；但事实上，为了保证消息的高可靠会有重试；  
Consumer 消费完，更新Offset失败，会导致其他Consumer消费队列重复消费  
综上，消息重复不可避免。  
3）如何保证MQ重复消费的幂等性 
改造业务逻辑，即重复消息不会影响业务逻辑。  

- SQL条件前置判断，或通过消息的version与数据库中version对比

- 全局唯一ID：数据正常入库，通过定时任务生成刷新视图，过滤掉重复数据。

- 数据库唯一键约束

- 记录处理过的ID，如果ID过来，先判断ID 是否有处理，处理过就丢弃。
- 如果写Redis，set是天然幂等的。  

## 如何保证消息的顺序性
消息存在顺序，放入消息队列后，到达消费者的时间不同，入库时间不同，造成业务问题。  
（1）RabbitMQ  
现象：顺序数据A->B-C，放到一个Queue中，被多个消费者消费，导致数据顺序错乱。  
方案：指定每个Queue对应一个消费者，保证数据入队是顺序的，单消费者消费就不会有顺序问题。  
（2）Kafka  
现象：写有序：kafka 一个topic下有多个partition，kafka可以保证partition下的数据是有序的，所以Producer在写数据的时候指定key，可以保证数据放入一个partition。
读有序：每个partition由一个Consumer消费，所以消费者消费数据是有序的。  
处理无序：但消费者内部使用多线程消费，会导致消费者消息错乱。  
方案：依然使用多线程并发，需要引入内存队列，将相同类型的消息存入相同队列，每个内存队列被一个线程处理，即可保证消息的顺序性。  

## 如何解决消息队列的延时以及过期失效问题?消息队列满了以后该怎么处理?有几百万消息持续积压几小时,说说怎么解决?
现象：消费端有问题了，产生了消息积压。  
1. 延迟或过期失效：rabbitMQ可以设置消息过期时间，消息大量积压，导致过期都丢弃了，造成数据丢失，不建议设置。晚上临时写程序，一点一点将丢失的数据查出来，手动发到MQ中补一次。  
2. 消息队列满了：临时写程序，接入数据来消费，消费一个丢弃一个，快速消费所有的消息；然后，晚上再补数据，从第1步过程。  
3. 快速处理积压的消息，具体步骤如下：  
1）修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉。  
2）新建一个topic，partition是原来的10倍，原先10倍的queue，临时写一个分发的consumer，将积压消息分发到10倍的临时partition中。临时征用10倍的机器部署consumer，每个consumer消费一个临时queue，相当于10倍的消费速度。  
3）消费处理完成后，还原成原来的部署。  
总结：先消除消费者bug，提高消费速度，最后增加Topic 队列和消费者。

## 设计MQ 的思路
比如说这个消息队列系统,我们从以下几个角度来考虑一下:  
（1）扩展性：首先这个mq 得支持**可伸缩性**吧,就是需要的时候快速扩容,就可以增加吞吐量和容量,那怎么搞?设计个分布式的系统呗,参照一下 kafka 的设计理念,broker -> topic -> partition,每个 partition 放一个机器,就存一部分数据。  
如果现在资源不够了,简单啊,给 topic 增加partition,然后做数据迁移,增加机器,不就可以存放更多数据,提供更高的吞吐量了?  
（2）持久化：其次你得考虑一下这个 mq 的数据要不要**落地磁盘**吧?那肯定要了,落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊?顺序写,这样就没有磁盘随机读写的寻址开销,磁盘顺序读写的性能是很高的,这就是 kafka 的思路。  
（3）高可用机制：其次你考虑一下你的 mq 的**可用性**啊?这个事儿,具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。  
（4）高可靠性：能不能支持**数据0丢失**啊?可以的,参考kafka 数据零丢失方案。

## Kafka
### 如何获取topic 主题列表
kafka-topics.sh --list --zookeeper localhost:2181
### 生产者和消费者命令
生产者在topic 上发布消息：kafka-console-producer.bat --broker-list localhost:9092 --topic kafka-test-topic  
消费者：kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic kafka-test-topic --from-beginning  
### Consumer 是推还是拉？  
Producer 从brokers 推送消息；Consumer 从brokers pull 拉取消息；  
原因：  
1）一些消息系统采用push模式，有好有坏：由broker决定消息推送的速率，对于不同处理速率的Consumer不太好处理。当broker推送速率远大于Consumer的处理速率，Consumer可能会崩溃，所以kafka使用了pull模式。  
2）Consumer可以自行决定是否批量从broker拉取数据，push 模式在无法得知Consumer的处理能力；pull模式可以让Consumer根据自身资源情况，拉取数据，单条、批量拉取数据。  
3）缺点：当broker无消息时，Consumer也在轮询等待新消息，造成资源浪费。  
解决：通过参数设置，consumer拉取数据为空或者没有达到一定数量时进行阻塞。 
### Kafka 维护消费状态跟踪状态的方法  
普通消息系统：broker端维护消息被消费的记录，这样消息在被消费后，删除消息释放空间。  
存在以下问题：  
1）消息发送之后，标记为已消费，若程序消费失败，消息丢失，不可取；所以，一般为消息发送后为已发送状态，消费者消费成功后标记为已消费状态。  
2）通过1）可以避免消息丢失，但是会产生消息重复消费；而且，broker必须维护这条消息的状态，每次必须锁定状态并更新状态然后释放锁，若程序无响应，消息会被锁定。  
kafka采用了不同策略，topic 分成不同区，每个区在同一时间只能被一个Consumer消费；这样每个分区被消费的消息在日志中的位置仅仅是一个简单的整数：offset，很容易表示分区是否被消费，消费状态就更容易了。  
### 主从复制  
kafka 允许topic的分区拥有若干副本，可以配置。kafka会在每个副本上备份数据，当某个节点down，数据依然可用。副本功能不是必须的，可以手动配置。  
### 为什么需要消息系统？mysql 不行吗？  
1）解耦：系统解耦，两边的处理过程相互独立，统一接口约束  
2）异步处理：消息的异步处理，有些消息并不需要实时处理  
3）扩展性：类似ESB，可以很方便的增加处理系统Consumer或Producer  
4）流量削峰：针对突发的访问压力，使得系统不会因为超负荷请求导致崩溃  
5）可恢复性：系统一部分服务不可用，消息会存放在队列里，服务上线后可以继续处理  
6）顺序保证：数据可以按照特定的顺序处理，kafka 每个分区的消息都是有序的  
7）缓冲：缓解生产者和消费者处理不一致的情形
### Zookeeper 对于 Kafka 的作用
zk 是分布式协调工具，用于kafka 分布式应用中，用户节点通讯。  
在kafka有以下作用：  
1）/broker/ids：临时节点，存储broker的基本信息  
2）leader检测和管理，leader选举  
3）节点管理：识别节点的上线和下线，管理节点实时状态  
### 数据传输的事务定义有哪三种？
MQTT （Message Queuing Telemetry Transport（消息队列遥测传输）是一种基于发布/订阅范式的“轻量级”消息协议） 一样，有三种：  
1）最多一次：消息不会被重复发送，最多一次，可能没有  
2）最少一次：消息不会漏发，最少一次，可能重复发送  
3）精确的一次：不重复也不会漏发（期望）  
### Kafka如何判断某个节点存活？
1）Zookeeper有心跳检测机制，节点需要维护与zk 的连接  
2）如果节点是Follower，必须及时同步leader的写操作，延迟不能太大  
### Kafka 与传统MQ 的区别
1）持久化日志，可以被重复读取和无限期保留  
2）分布式系统：集群方式运行，灵活伸缩，内部通过数据复制同步，提高可用性  
3）支持实时流式处理  
### Kafka 的ack 三种机制
request.required.acks 有三个值 0 1 -1  
0：生产者不会等待broker 的ack，延迟最低，但可能造成消息丢失  
1：服务端等待ack值 leader副本接收到消息后发送ack，但不保证复制完成新的leader，也会导致数据丢失  
-1：服务端会等所有Follower的副本收到数据后才会收到leader 的ack，数据不会丢失  
### 消费者如何不自动提交偏移量，由应用提交？
1）auto.commit.offset=false  
2）消息处理后，同步commitSync或异步 commitAsync 提交  
### 消费者故障，出现活锁如何解决？
活锁：消费节点一直发送心跳，但不处理。为了预防这种一直持有分区的情况，使用 max.poll.interval.ms 活跃检测机制。  
如果你调用的 poll 的频率大于最大间隔，则客户端将主动地离开组，以便其他消费者接管该分区。  
消费者提供两个配置设置来控制 poll 循环：  
max.poll.interval.ms：增大 poll 的间隔，可以为消费者提供更多的时间去处理返回的消息（调用
poll(long)返回的消息，通常返回的消息都是一批）。缺点是此值越大将会延迟组重新平衡。  
max.poll.records：此设置限制每次调用 poll 返回的消息数，这样可以更容易的预测每次 poll 间隔要处理的最大值。
### 如何控制消费的位置
kafka使用seek(TopicPartition, long)指定新的消费位置。用于查找服务器保留的最早和最新的 offset的特殊的方法也可用（seekToBeginning(Collection) 和seekToEnd(Collection)）
### Kafka 如何保证顺序消费
1）Kafka 分布式的单位是 partition，同一个 partition 用一个 write ahead log 组织，所以可以保证 FIFO的顺序。  
2）不同 partition 之间不能保证顺序。但是绝大多数用户都可以通过 message key 来定义，因为同一个 key 的 message 可以保证只发送到同一个 partition。Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同 1个 partition，就是有序的。并且在消费端，Kafka 保证，1 个 partition 只能被1 个 consumer 消费。或者你指定 key（ 比如 order id），具有同 1 个 key的所有消息，会发往同 1 个 partition。
### 高可用机制是什么
1）系统特点：持久化日志，分布式集群，  
2）leader 和 Follower关系：leader 负责写，follower 从leader 同步数据，并提供数据的读取  
3）消息读写的顺序：写分区，读分区指定分区
### kafka 如何减少数据丢失
kafka 有可能会丢失数据，通常不会。可以配置参数较好的保证数据的持久性，牺牲吞吐量。  
1）acks=all，确认模式为-1  
2）retries = MAX_VALUE：最大重试次数  
3）使用KafkaProducer.send(record, callback)：callback逻辑中显式关闭producer：close(0)  
4）enable.auto.commit=false：消息处理完成之后再提交位移
### kafka 如何保证不重复消费
基于业务的角度  
1）如果是数据库，数据库唯一主键  
2）如果是redis，每次set 都是幂等的  
3）消息有唯一主键id，每次根据id 去redis（set 去重列表，add失败则已经消费过）里判断是否已经消费过，若消费过，就不再消费了。
### kafka 性能好在什么地方
1. 分布式系统
2. 消息堆积能力强：不基于内存，而是硬盘存储
3. 磁盘顺序写速度非常快，消息都是append，partition 是有序的。